{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changable Variables\n",
    "Set the path to the model and any unused categories to get information about the model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"\"\n",
    "unused_categories = [4, 5, 7, 8, 9, 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports & Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from image_sequences import BasicImageSequence\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from pathlib import Path\n",
    "from preliminary_caching import read_cached_data, filter_emotion_data\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import matplotlib.image as mpimg\n",
    "import fairface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_emotion = {\n",
    "    0: \"neutral\",\n",
    "    1: \"happy\",\n",
    "    2: \"sad\",\n",
    "    3: \"surprise\",\n",
    "    4: \"fear\",\n",
    "    5: \"disgust\",\n",
    "    6: \"angry\", \n",
    "    7: \"contempt\", \n",
    "    8: \"none\",\n",
    "    9: \"uncertain\",\n",
    "    10: \"noface\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Predictions\n",
    "\n",
    "Predictions are generated on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(model_path)\n",
    "\n",
    "validation_data = read_cached_data(\"validation\")\n",
    "\n",
    "# Filter out emotions that the model may not have been trained on\n",
    "if len(unused_categories) > 0:\n",
    "    validation_data = filter_emotion_data(validation_data, unused_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_generator = BasicImageSequence(validation_data)\n",
    "\n",
    "# This can take a few minutes to run.\n",
    "prediction = model.predict_generator(validation_generator, steps = len(validation_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The images are in the same order as the map for the first iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes = np.argmax(prediction, axis=1)\n",
    "actual_classes = np.array(list(map(lambda it: it[\"emotion\"], validation_data.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference = predicted_classes - actual_classes \n",
    "wrong = np.count_nonzero(difference)\n",
    "correct = len(difference) - wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy: {correct / len(difference)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = confusion_matrix(actual_classes, predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap(data,labels_x, labels_y,title, title_x,title_y):\n",
    "    ax = sns.heatmap(data,annot = True, xticklabels=labels_x, yticklabels=labels_y)\n",
    "    plt.title(title, fontsize = 20)\n",
    "    plt.xlabel(title_x, fontsize = 15)\n",
    "    plt.ylabel(title_y, fontsize = 15)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_ids = [x for x in list(range(11)) if x not in unused_categories]\n",
    "labels = list(map(lambda x: id_to_emotion[x], label_ids))\n",
    "heatmap(matrix, labels, labels, \"Confusion Matrix\", \"Predicted\", \"Actual\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate P Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "wrong = matrix[np.logical_not(np.eye(matrix.shape[0],dtype = bool))].reshape((matrix.shape[0],matrix.shape[1]-1))\n",
    "uniform = np.ones(wrong.shape)*np.ceil(np.sum(wrong,axis = 1)[:,np.newaxis]/wrong.shape[1])\n",
    "p_values = []\n",
    "for i in range(wrong.shape[0]):\n",
    "    _,p,_,_ = chi2_contingency([wrong[i],uniform[i]])\n",
    "    p_values.append(p)\n",
    "print(p_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Wrong Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_indexs = np.nonzero(difference)[0]\n",
    "\n",
    "def visualize_wrong_image(index):\n",
    "    \n",
    "    predicted = id_to_emotion[predicted_classes[index]]\n",
    "    actual = id_to_emotion[actual_classes[index]]\n",
    "    image_path = list(validation_data.keys())[index]\n",
    "    \n",
    "    image = mpimg.imread(image_path)\n",
    "    plt.title(f\"Actual: {actual} Predicted: {predicted}\")\n",
    "    plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_index = random.randint(0, len(wrong_indexs))\n",
    "visualize_wrong_image(wrong_indexs[random_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Accuracy Stratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stacked_barchart(data, labels_x, labels_y,title, title_x,title_y):\n",
    "    figure = plt.figure()\n",
    "    figure.set_figwidth(10)\n",
    "    figure.set_figheight(10)\n",
    "    xloc = np.arange(len(labels_x))\n",
    "    plt.xticks(xloc,labels_x)\n",
    "    legend = []\n",
    "    bottom = np.zeros(len(labels_x))\n",
    "    for i in range(data.shape[0]):\n",
    "        p = plt.bar(xloc,data[i],bottom = bottom, width = 0.5)\n",
    "        bottom += data[i]\n",
    "        legend.append(p[0])\n",
    "    plt.legend(legend,labels_y)\n",
    "    plt.title(title, fontsize = 20)\n",
    "    plt.xlabel(title_x, fontsize = 15) \n",
    "    plt.ylabel(title_y, fontsize = 15) \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratify_accuracy(class_name, name_mapping_function):\n",
    "    \n",
    "    total_predictions = dict()\n",
    "    correct_predictions = dict()\n",
    "    \n",
    "    for index, image_data in enumerate(validation_data.values()):\n",
    "        class_id = image_data[class_name]\n",
    "        total_predictions[class_id] = total_predictions.get(class_id, 0) + 1\n",
    "        \n",
    "        if difference[index] == 0:\n",
    "            correct_predictions[class_id] = correct_predictions.get(class_id, 0) + 1\n",
    "        \n",
    "    accuracies = dict()\n",
    "        \n",
    "    for class_id in total_predictions:\n",
    "        \n",
    "        accuracy = correct_predictions.get(class_id, 0) / total_predictions[class_id] \n",
    "        label = name_mapping_function(class_id)\n",
    "        accuracies[label] = accuracy\n",
    "    \n",
    "    return accuracies\n",
    "\n",
    "gender_accuracies = stratify_accuracy(\"gender\", fairface.gender_label)\n",
    "age_accuracies = stratify_accuracy(\"age\", fairface.age_label)\n",
    "race7_accuracies = stratify_accuracy(\"race\", fairface.race7_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_barchart(\n",
    "    np.array([\n",
    "        list(gender_accuracies.values()),\n",
    "        list(map(lambda x: 1 - x, gender_accuracies.values()))\n",
    "    ]),\n",
    "    list(gender_accuracies.keys()),\n",
    "    [\"Correct\", \"Wrong\"],\n",
    "    \"Accuracies by Gender\",\n",
    "    \"Predicted Labels\",\n",
    "    \"Actual Labels\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_barchart(\n",
    "    np.array([\n",
    "        list(age_accuracies.values()),\n",
    "        list(map(lambda x: 1 - x, age_accuracies.values()))\n",
    "    ]),\n",
    "    list(age_accuracies.keys()),\n",
    "    [\"Correct\", \"Wrong\"],\n",
    "    \"Accuracies by Age\",\n",
    "    \"Predicted Labels\",\n",
    "    \"Actual Labels\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_barchart(\n",
    "    np.array([\n",
    "        list(race7_accuracies.values()),\n",
    "        list(map(lambda x: 1 - x, race7_accuracies.values()))\n",
    "    ]),\n",
    "    list(race7_accuracies.keys()),\n",
    "    [\"Correct\", \"Wrong\"],\n",
    "    \"Accuracies by Race\",\n",
    "    \"Predicted Labels\",\n",
    "    \"Actual Labels\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
